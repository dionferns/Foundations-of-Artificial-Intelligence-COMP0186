{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a458f3ee",
   "metadata": {},
   "source": [
    "# COMP186: Foundations of Artificial Intelligence Individual Coursework\n",
    "\n",
    "### Authors: Sahan Bulathwela, Hossein A. (Saeed) Rahmani, Xiao Fu and Joshua Spear\n",
    "\n",
    "#### Contact: \n",
    "\n",
    "NB: Please do **not** discuss the Coursework in the forum or any other public medium. Please ask directly during office hours or any time via an email directed to the TA assigned to the part of the assignment. The tutor and the TAs will respond either via email or via a public announcement to all students.\n",
    "\n",
    "If you have any questions/clarifications regarding the coursework, please contact the TA responsible for that part of the coursework **via email**. \n",
    "- Part 1: Wiem Ben Rim (wiem.rim.23@ucl.ac.uk)\n",
    "- Part 2: Xiao Fu (xiao.fu.20@ucl.ac.uk)\n",
    "- Part 3: Lynn Kandakji (l.kandakji.22@ucl.ac.uk)\n",
    "\n",
    "- General Clarifications: Sahan Bulathwela (m.bulathwela@ucl.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786b1a2",
   "metadata": {},
   "source": [
    "This coursework presents a real-world dataset to the learners where they are expected to systematically develop a model that can make good predictions. The coursework attempts to test both the theoretical and practical understanding of the learners regarding training machine learning models. \n",
    "\n",
    "## Coursework Structure\n",
    "\n",
    "This coursework consists of three parts. \n",
    "\n",
    "1. Exploratory data analysis and data preparation\n",
    "2. Model training and evaluation\n",
    "3. Demonstrating the theoretical understanding of a regression model\n",
    "\n",
    "Parts 1 and 2 of the coursework involves multiple subtasks of building a machine learning model from data preparation to model evaluation. Part 3 systematically assists the learner to take their mathematical understanding of machine learning and build learning algorithms from scratch. \n",
    "\n",
    "## Guidelines to Providing Solutions\n",
    "\n",
    "- This is an **INDIVIDUAL** coursework.\n",
    "- The main questions are marked in $\\color{red}{red}$ to improve visibility (e.e. $\\color{red}{Question\\ x.x}$).\n",
    "- This coursework consists of 3 parts where Part 1 and 2 carry 30 marks each and part 3 carries 40 marks.\n",
    "- Each part will be marked **independently**. For example, Part 2 will be marked based solely on the code and answers provided within Part 2; answers from Part 1 or part 3 will not be considered.  \n",
    "- It is expected that learners provide solutions to **ALL** parts of the coursework **in this notebook itself**.\n",
    "- The learners are expected to provide solutions in this Jupyter notebook itself (Both Code and text answers.).\n",
    "- The solutions should be provided in the spaces provided. You may add new cells where it is necessary.\n",
    "- Cells where answers are required in English text is marked with `Your Answer Here`\n",
    "    - You can use markdown language to add formatting to your text. A cheat sheet is found [here](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n",
    "    - Where you feel that mathematical notation is required, you can use latex syntax (e.g. `$x = 2^5$`:  $x = 2^5$)\n",
    "    - Alternatively, you are allowed to attach a image of your mathematical derivations.\n",
    "- Cells where program code is expected, it is marked with `Your Code Here`.\n",
    "    - You are expected to provide solutions in **Python** programming language\n",
    "    - You should implement the code in a way that the function signature is preserved where the function skeleton is already provided (ie, mainly 1) function name 2) input parameters and 3) output parameters). \n",
    "    - Where external datasets are used, use their **relative path** in the code. This simplifies reproducing results during assessment.\n",
    "    - Use commenting (`# example comment here`) to describe the crucial steps in your programming code. This will help the examiner to understand your work. \n",
    "    \n",
    "## Uploading Solutions\n",
    "\n",
    "- It is expected that a **single** `.zip` file is uploaded as the solution. \n",
    "- Zip the **same folder** that was provided as the assignment.\n",
    "- The zipped directory should have the following files.\n",
    "    - The completed assignment notebook (With Python code and English Text)\n",
    "    - A PDF printout of the solutions notebook where all the output cells have been executed and the solution outputs are visible in the notebook. (**THIS IS NOT A SEPARATE  PDF REPORT !!!**)\n",
    "    - The `lectures_dataset.csv`dataset CSV file (in the same relative file location where the file can be loaded to the notebook by executing the relevant cell in the solution notebook.)\n",
    "    - Any additional data files you generated that become input to your solutions (put the files in the relative file locations that will allow loading the files to the notebook to execute your solution.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10cc8ce",
   "metadata": {},
   "source": [
    "## Video Lectures Dataset\n",
    "\n",
    "This coursework works with a collection of video lectures. Different characteristics identified from the meta data, video data and transcripts of the lectures are included in the `lectures_dataset.csv` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"lectures_dataset.csv\"\n",
    "lectures = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13494b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ce798",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lectures.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d7797",
   "metadata": {},
   "source": [
    "- The dataset contains 11,548 observations 21 potential features and 1 label column. The label we are aiming to predict is `median_engagement` which can take a value between 0 and 1 where values close to 0 exhibit low engagement and values close to 1 indicate high engagement.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666a5fd",
   "metadata": {},
   "source": [
    "### Description of Columns\n",
    "\n",
    "The following table describes the columns in the dataset.\n",
    "\n",
    "|      **Variable Name**     |     **Type**     |\n",
    "|:--------------------------:|:----------------:|\n",
    "| auxiliary_rate             | Fraction of auxiliary verbs in the transcript |\n",
    "| conjugate_rate             | Fraction of conjugates in the transcript |\n",
    "| normalization_rate         | Fraction of normalisation suffixes used in the transcript |\n",
    "| tobe_verb_rate             | Fraction of to-be-verbs in the transcript |\n",
    "| preposition_rate           | Fraction of prepositions in the transcript |\n",
    "| pronoun_rate               | Fraction of pronouns words in the transcript |\n",
    "| document_entropy           | Document entropy computed using word counts (Topic coherence) |\n",
    "| easiness                   | The reading level of the transcript (level of English) |\n",
    "| fraction_stopword_coverage | Fraction of unique stopwords used in the transcript |\n",
    "| fraction_stopword_presence | Fraction of stopwords in the transcript |\n",
    "| subject_domain             | If the subject belongs to STEM or not. |\n",
    "| freshness                  | How recently the video published |\n",
    "| title_word_count           | Number of words in the title |\n",
    "| word_count                 | Number of words in the transcript |\n",
    "| most_covered_topic         | The Wikipedia URL of the most covered topic |\n",
    "| topic_coverage             | To what degree is the most covered topic covered |\n",
    "| duration                   | Duration of the video |\n",
    "| lecture_type               | Type of lecture (e.g. lecture, tutorial, debate, discussion etc.) |\n",
    "| has_parts                  | If the lecture is broken into multiple videos |\n",
    "| speaker_speed              | The word rate of the speaker (words per minute) |\n",
    "| silent_period_rate         | Fraction of Silence in the transcript where words are not spoken |\n",
    "| median_engagement          | Median % of video watched by all the viewers who watched it |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071060a",
   "metadata": {},
   "source": [
    "# Part 1: Exploratory Data Analysis and Feature Extraction (30 Marks)\n",
    "\n",
    "This section attempts to understand the dataset before we jump into building a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d1375",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 1.1.}$ What are the different data types each variable in the dataset belong to? \n",
    "There are different data types different variables fall into. Based on these data types, we may handle these variables differently. In this question, you are expected to identify which data type each variable in the lecture dataset belongs to. \n",
    "- Replace the `Your Answer Here` with your answer\n",
    "- Possible values: Continuous, Discrete, Ordinal and Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88cdb1d",
   "metadata": {},
   "source": [
    "|      **Variable Name**     |     **Type**     |\n",
    "|:--------------------------:|:----------------:|\n",
    "| auxiliary_rate             | **Your Answer Here** |\n",
    "| conjugate_rate             | **Your Answer Here** |\n",
    "| normalization_rate         | **Your Answer Here** |\n",
    "| tobe_verb_rate             | **Your Answer Here** |\n",
    "| preposition_rate           | **Your Answer Here** |\n",
    "| pronoun_rate               | **Your Answer Here** |\n",
    "| document_entropy           | **Your Answer Here** |\n",
    "| easiness                   | **Your Answer Here** |\n",
    "| fraction_stopword_coverage | **Your Answer Here** |\n",
    "| fraction_stopword_presence | **Your Answer Here** |\n",
    "| subject_domain             | **Your Answer Here** |\n",
    "| freshness                  | **Your Answer Here** |\n",
    "| title_word_count           | **Your Answer Here** |\n",
    "| word_count                 | **Your Answer Here** |\n",
    "| most_covered_topic         | **Your Answer Here** |\n",
    "| topic_coverage             | **Your Answer Here** |\n",
    "| duration                   | **Your Answer Here** |\n",
    "| lecture_type               | **Your Answer Here** |\n",
    "| has_parts                  | **Your Answer Here** |\n",
    "| speaker_speed              | **Your Answer Here** |\n",
    "| silent_period_rate         | **Your Answer Here** |\n",
    "| median_engagement          | **Your Answer Here** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cc20b",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 1.2.}$ Analyse the variables to understand them.\n",
    "This question expects you to carry out `exploratory data analysis` on the dataset to understand the data and the value distributions better. This enables us to carry out specific pre-processing steps. \n",
    "- List the analyses you would carry out with the features and the labels of the dataset. Justify why you think the proposed analyses are appropriate. \n",
    "- Carry Out the Analyses you proposed. \n",
    "    - **You are NOT permitted to use data analysis libraries that automatically run a brute-force set of analyses on the entire dataset. Usage of such libraries will be penalised.**\n",
    "    - You may use visualisation libraries such as `matplotlib`, `plotly`, `seaborn` etc.\n",
    "    - You may also use data processing libraries such as `pandas`, `numpy`, `scipy` etc.\n",
    "    - You are expected to do as many analyses as you feel necessary to understand the data to make informed decisions about preprocessing.\n",
    "    - You may use as many code cells as you deem necessary here to carry out your analysis. However, do not include analyses that are not meaningful for understanding the dataset (ones that you are unable to justify).\n",
    "    - Use a markdown cell on top of the code cells to describe the analysis you are carrying out and its justification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab3425",
   "metadata": {},
   "source": [
    "#### Choice of Analyses to be carried out with justification\n",
    "1. **Your Answer Here**\n",
    "2. **Your Answer Here**\n",
    "3. **Your Answer Here**\n",
    "4. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f92f9d",
   "metadata": {},
   "source": [
    "#### Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d323d0",
   "metadata": {},
   "source": [
    "#### Analysis 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a207d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72bb36d",
   "metadata": {},
   "source": [
    "#### Question \n",
    "\n",
    "Summarise the key findings of your analyses.\n",
    "\n",
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f19d68",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 1.3.}$ Derive conclusions from your analyses and implement data preprocessing.\n",
    "This question expects you to derive conclusions and implement preprocessing steps based on the analyses carried out in the previous question. Use the markdown cell to propose preprocessing steps and the code cell to implement the preprocessing function.  \n",
    "- Based on the results obtained in the previous section, identify noteworthy observations (e.g. missing values, outliers etc.)? Describe what you observed and the implications.  \n",
    "- How are you going to preprocess the dataset based on these observations? Justify your preprocessing steps in relation to the analyses. \n",
    "- In the subsequent code cell, implement the `preprocess_lecture_dataset` function to take the entire dataset as input and carry out preprocessing\n",
    "- You may use additional code cells to implement sub-functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c875c",
   "metadata": {},
   "source": [
    "#### Question: Justification\n",
    "\n",
    "**Your Answer Here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac32027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lecture_dataset(dataset):\n",
    "    \"\"\"\n",
    "    takes the lecture dataset and transforms it with necessary pre-processing steps.\n",
    "    \n",
    "    Params: \n",
    "        dataset (pandas.DataFrame): DataFrame object that contains the original dataset provided for the coursework\n",
    "        \n",
    "    Returns:\n",
    "        preprocessed_dataset (pandas.DataFrame): DataFrame object that contains the dataset after data \n",
    "                                                pre-processing has been carried out\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lectures = preprocess_lecture_dataset(lectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0dc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lectures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5075cbd",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 1.4}$ Numerically encode the dataset for model training.\n",
    "This question expects you to create the final numerical dataset you will use to carry out model training with ridge regression.\n",
    "\n",
    "- Implement the `prepare_final_dataset` function to transform different features.\n",
    "- Features that belong to different data types need to be transformed to an ideal numerical representation\n",
    "- You may use helper functions in `scikit-learn` machine learning library to implement this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_final_dataset(preprocessed_dataset):\n",
    "    \"\"\"\n",
    "    takes the preprocessed lecture dataset and transforms it to the vector representation.\n",
    "    \n",
    "    Params: \n",
    "        preprocessed_dataset (pandas.DataFrame): DataFrame object that contains the original \n",
    "                                                dataset provided for the coursework\n",
    "        \n",
    "    Returns:\n",
    "        X (pandas.DataFrame): DataFrame object that contains the features\n",
    "        y (numpy.array): List of labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return preprocessed_dataset, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset, full_X, full_y = prepare_final_dataset(preprocessed_lectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45663c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d68108",
   "metadata": {},
   "source": [
    "Let us now save the final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57965023",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X.to_csv(\"features_final.csv\", index=False)\n",
    "np.save(\"labels_final.npy\", full_y.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c40d3b",
   "metadata": {},
   "source": [
    "# Part 2: Modeling and Evaluation (30 Marks)\n",
    "\n",
    "In this section, we develop a model using the preprocessed data. We start by loading the data that we saved in the previous part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = pd.read_csv(\"features_final.csv\")\n",
    "full_y = np.load(\"labels_final.npy\")\n",
    "\n",
    "# If you didn't manage to save the preprocessed data structures from part one. \n",
    "# You can start the exercise with alternative data. But the performance will be very low. \n",
    "\n",
    "# full_X = pd.read_csv(\"features_seed.csv\")\n",
    "# full_y = np.load(\"labels_seed.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c4b2e",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 2.1}$ Train Ridge Regression Model.\n",
    "In this question, you are expected to derive a trained ridge regression model. \n",
    "\n",
    "- Implement the `train_model` function to output the trained ridge regression model.\n",
    "- You may use helper functions and models in `scikit-learn` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e12ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_model(X,y, hyperparams):\n",
    "    \"\"\"\n",
    "    takes the training data with the hyper-parameters to train the ridge model\n",
    "    \n",
    "    Params: \n",
    "        X (pandas.DataFrame): DataFrame object that contains the features\n",
    "        y (numpy.array): List of labels\n",
    "        hyperparams (dict): a dictionary of hyperparameters where the key is the hyperparameter name, \n",
    "                            and the value is the hyperparameter value\n",
    "        \n",
    "    Returns:\n",
    "        ridge_model(scikit-learn model): A trained scikit-learn model object\n",
    "        :\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return ridge_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48e652",
   "metadata": {},
   "source": [
    "- Define the python dictionary `hyperparams` with the hyperparameters needed for Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe79c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    # Your Code Here\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6080318",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ridge_model = train_ridge_model(full_X, full_y, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3c414",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 2.2}$ Gaussian (RBF) Kernel Regression Model\n",
    "In this question, you are expected to implement the Gaussian (Radial Basis Function/ RBF) kernel and use it with Ridge Regression to train a Kernel Ridge model that uses the Gaussian Kernel. \n",
    "\n",
    "- Implement the `gauss_kernel` function to output the similarity between two points (`x` and `x_dash`) using the Gaussian kernel. \n",
    "- You may use helper functions `numpy` and `scipy` libraries to speed up matrix computations. But the function should be implemented by you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8285e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_kernel(x, x_dash, gamma):\n",
    "    \"\"\"\n",
    "    takes two data points and calculates their similarity using the RBF function. \n",
    "    \n",
    "    params: \n",
    "        x (numpy.array): point 1 coordinates \n",
    "        x_dash (numpy.array): point 2 coordinates\n",
    "        gamma : relevant hyperparameter for the Gaussian Kernel\n",
    "        \n",
    "    returns:\n",
    "        similarity (float): similarity between the two points\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d68d9",
   "metadata": {},
   "source": [
    "- Implement the `train_kernel_ridge_model` function to output the trained kernel ridge regression model. \n",
    "- Use the relevant parameters in the [`sklearn.kernel_ridge.KernelRidge`](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn-kernel-ridge-kernelridge) function to pass the `gauss_kernel` function implemented earlier with kernel regression.\n",
    "- Training this model may take some time ($\\approx$ 10 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9dcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kernel_ridge_model(X,y, hyperparams, kernel_function, kernel_params):\n",
    "    \"\"\"\n",
    "    takes the training data with the hyper-parameters to train the ridge model\n",
    "    \n",
    "    Params: \n",
    "        X (pandas.DataFrame): DataFrame object that contains the features\n",
    "        y (numpy.array): List of labels\n",
    "        hyperparams (dict): a dictionary of hyperparameters where the key is the hyperparameter name, \n",
    "                            and the value is the hyperparameter value\n",
    "        kernel_function (callable): a callable python function which is the kernel function\n",
    "        kernel_params (dict): a dictionary of kernel parameters where the key is the kernel parameter name, \n",
    "                            and the value is the parameter value\n",
    "        \n",
    "    Returns:\n",
    "        kernel_ridge_model(scikit-learn model): A trained scikit-learn model object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return kernel_ridge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"alpha\" : 0.1\n",
    "}\n",
    "\n",
    "kernel_params = {\n",
    "    \"gamma\" : 1e-2\n",
    "}\n",
    "\n",
    "temp_kernel_ridge_model = train_kernel_ridge_model(full_X, full_y, hyperparams, gauss_kernel, kernel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c09105",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y = temp_kernel_ridge_model.predict(full_X)\n",
    "print(temp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a542e",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 2.3}$ Propose and Implement two evaluation metrics that are suitable for model evaluation in this task. \n",
    "This question expects you to propose two evaluation metrics that can be used to assess predictive capabilities in this task and implement them.\n",
    "\n",
    "- Propose two metrics by replacing `Your Answer Here`. You are encourage to propose metrics that go beyond the ones taught in class. \n",
    "- implement the two metrics while renaming function names from `eval_metric_1` and `eval_metric_2` to the metrics you are proposing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22bdf46",
   "metadata": {},
   "source": [
    "**Metric 1**\n",
    "\n",
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8677b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_1(y_actual, y_predicted)\n",
    "    \"\"\"\n",
    "    returns the evaluation metric. \n",
    "    \n",
    "    Params: \n",
    "        y_actual (numpy.array): List of actual labels\n",
    "        y_predicted (numpy.array): List of predicted labels\n",
    "    \n",
    "    Returns:\n",
    "        metric (float): the evaluation metric\n",
    "    \"\"\"\n",
    "\n",
    "    # Your Code Here\n",
    "    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc608f",
   "metadata": {},
   "source": [
    "**Metric 2**\n",
    "\n",
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_2(y_actual, y_predicted)\n",
    "    \"\"\"\n",
    "    returns the evaluation metric. \n",
    "    \n",
    "    Params: \n",
    "        y_actual (numpy.array): List of actual labels\n",
    "        y_predicted (numpy.array): List of predicted labels\n",
    "    \n",
    "    Returns:\n",
    "        metric (float): the evaluation metric\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b89474",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 2.4}$ Evaluate the performance of the Ridge Regression model to detect overfitting. \n",
    "In this question, you are expected to implement a function to evaluate the predictive performance of a trained Ridge Regression model and detect if overfitting is evident. \n",
    "\n",
    "- Implement the `evaluate_ridge_model` function to take in the lectures data and\n",
    "    - Handle the data carefully before training the model\n",
    "    - Design a pipeline that incorporates comprehensive techniques to ensure robust and reliable model training and evaluation.\n",
    "    - train the model \n",
    "    - evaluate the model using the proposed metrics and \n",
    "    - print the relevant information to assess model performance (including overfitting)\n",
    "- The function does NOT have to return anything. Make sure it prints the relevant metrics instead. \n",
    "- You are expected to design the training methodology to end up training the most generalisable model from the data provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c362787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ridge_model(X,y):\n",
    "    \"\"\"\n",
    "    trains the most viable model using the lecture data for median engagement prediction to evaluate it using the proposed metrics. \n",
    "    \n",
    "    Params:\n",
    "        X (pandas.DataFrame): features of the dataset\n",
    "        y (numpy.array): labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df95656",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "- Is the model exhibiting overfitting? Justify your answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57471e07",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94fb13",
   "metadata": {},
   "source": [
    "# Part 3: Ridge Regression: From Theory to Implementation (40 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cfa7b6",
   "metadata": {},
   "source": [
    "In this section, we focus on understanding Ridge Regression better. Ridge Regression is the main modelling tool that we use throughout this coursework. It introduces a penalty to the objective of the model if the linear weights become too big. \n",
    "\n",
    "This part of the coursework expects the learner to gradually implement the ridge regression using matrix operations using python. This is expected to help the learners connect the mathematical derivations to the actual programmatic realisation of the learning algorithms. \n",
    "\n",
    "__Hints__: \n",
    "- All X,y inputs in the proceeding assumes multiple _observations_ are being passed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c08650",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We use a pre-created dataset for this part of the exercise. Let us load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b486e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = pd.read_csv(\"features_seed.csv\")\n",
    "full_y = np.load(\"labels_seed.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df6240",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 3.1}$ Transform the data to matrix representations that are suitable for training a Ridge Regression model.  \n",
    "In this question, you are expected to implement a function to prepare the feature and label data that we otherwise input to `scikit-learn` and prepare the matrix/vector representations.\n",
    "\n",
    "- Implement the `prepare_data_for_training` function to take in the features and labels and return feature matrix/vector and label matrix/vector back. \n",
    "    - the function should take `pandas.DataFrame` objects as input. These DataFrames should have the data values that are passed to the `fit()` function of the `scikit-learn` model (ie. after all the preprocessing and other transformations)\n",
    "    - you are expected to determine the suitable dimensionality for the output matrices\n",
    "- You must NOT use any `scikit-learn` or any other machine learning library's functions within this function. It will be penalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_training(X, y=None):\n",
    "    \"\"\"\n",
    "    returns the matrices that are passed in to the training function of the ridge regression.\n",
    "    \n",
    "    Params:\n",
    "        X (pandas.DataFrame): Features in the dataset\n",
    "        y (pandas.DataFrame): Labels in the dataset, Optional\n",
    "        \n",
    "    Returns:\n",
    "        X (numpy.array): X matrix/vector passed to the Ridge Regression training\n",
    "        y (numpy.array): y matrix/vector passed to the Ridge Regression training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00898248",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = prepare_data_for_training(full_X, full_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8396c3",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 3.2}$ Implement the training and prediction functions of the Ridge Regression model (primal form).  \n",
    "This question expects you to implement the training and prediction capabilities of the ridge regression model. \n",
    "\n",
    "- Implement the `fit_ridge_reg` function to take in the features, labels and the hyper-parameters to return the trained parameters of the model. \n",
    "- You are expected to use the Primal form when implementing the fitting step.\n",
    "- You are NOT allowed to use `scikit-learn` functions here. It will be penalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86aa869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ridge_reg(X, y, hyperparams):\n",
    "    \"\"\"\n",
    "     Params:\n",
    "        X (numpy.array): X matrix/vector passed to the Ridge Regression training\n",
    "        y (numpy.array): y matrix/vector passed to the Ridge Regression training\n",
    "        hyperparams (dict): a dictionary where the key is the hyperparameter name \n",
    "                            and values is the hyperparameter value\n",
    "        \n",
    "    Returns:\n",
    "       _theta (numpy.array): the trained parameters of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return _theta    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"lambda\": 0.001\n",
    "}\n",
    "\n",
    "theta = fit_ridge_reg(X_, y_, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of theta matrix/vector: {} \\n\\n The values are: \\n {}\".format(theta.shape, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bcf5d",
   "metadata": {},
   "source": [
    "- Implement the relevant parts of the `RidgeRegression` class below.\n",
    "    - add relevant object attributes including hyperparameters\n",
    "    - `fit` and `predict` functions need to be implemented as well \n",
    "- You may reuse the functions you implemented previously in this part of the assignment\n",
    "- You are NOT allowed to use `scikit-learn` functions here. It will be penalised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression():\n",
    "    def __init__(self, hyperparams):\n",
    "        \"\"\"\n",
    "        instantiates the class\n",
    "        \n",
    "        Params:\n",
    "            hyperparams (dict): a dictionary where the key is the hyperparameter name \n",
    "                            and values is the hyperparameter value\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fitted = False # indicates whether the model is already trained or not\n",
    "        \n",
    "        # Your Code Here\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        trains the model given the data. Updates  models internal parameters\n",
    "\n",
    "        Params:\n",
    "            X (pandas.DataFrame): Features in the dataset\n",
    "            y (pandas.DataFrame): Labels in the dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        # Your Code Here\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        makes predictions from given features. \n",
    "        ! The model should be trained first. Otherwise throws an error.\n",
    "\n",
    "        Params:\n",
    "            X (pandas.DataFrame): Features in the dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        # Your Code Here\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113eb1a-b5d4-4763-9228-cee283a99555",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"lambda\": 0.001\n",
    "}\n",
    "\n",
    "RR = RidgeRegression(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attributes of the RidgeRegression Instance Before Training: \\n{}\".format(RR.__dict__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3744ca4",
   "metadata": {},
   "source": [
    "- Train the model with the appropriate data using the `fit` function of the model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361624be",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR.fit(full_x, full_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attributes of the RidgeRegression Instance After Training: \\n{}\".format(RR.__dict__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5bf95f",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "\n",
    "- Get predictions from the trained model and show that the predictions have a linear correlation with the actual labels. For __this question__, you are allowed to use scientific computing packages such as `scikit-learn` or `sciPy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86bd0d",
   "metadata": {},
   "source": [
    "**Question**: Why did you use the above method? Justify your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8bed2b",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95727104",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 3.3}$ Ridge Regression in the Online Learning Setting\n",
    "In this question, we create several building blocks required to learn with Ridge Regression in an online setting using stochastic gradient descent. You are first expected to derive the first derivative of the Ridge Regression loss function. \n",
    "\n",
    "- Implement the `ridge_reg_loss_derivative` function to take in the features, labels, parameters, and hyperparameters, and return the first derivative $\\frac{\\delta \\mathcal{L}}{\\delta \\theta}$ of the loss function $ \\mathcal{L}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_reg_loss_derivative(X, y, theta, hyperparams):\n",
    "    \"\"\"\n",
    "    takes data, parameters and hyperparameters to calculate the first derivative of ridge loss\n",
    "    \n",
    "    Params:\n",
    "        X (numpy.array): a matrix/vector of features \n",
    "        y (numpy.array): a matrix/vector of labels \n",
    "        theta (numpy.array): a matrix/vector of parameters being trained \n",
    "        hyperparams (dict): a dictionary where the key is the hyperparameter name \n",
    "                            and values is the hyperparameter value\n",
    "                            \n",
    "    Returns:\n",
    "        derivative (numpy.array): the derivative used for updating the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb50208",
   "metadata": {},
   "source": [
    "- Implement the `train_stoch_ridge_reg` function to take data, parameters and hyperparameters  and return the updated theta\n",
    "- You are not allowed to use machine learning libraries such as `scikit-learn` or tensor computation libraries such as `tensorflow`, `keras`, `pytorch` etc. in this section. You will be penalised for using such libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf03e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stoch_ridge_reg(X, y, _theta, hyperparams):\n",
    "    \"\"\"\n",
    "    takes data, parameters and hyperparameters and returns the updated parameters \n",
    "    from training with data\n",
    "    \n",
    "    Params:\n",
    "        X (numpy.array): a matrix/vector of features \n",
    "        y (numpy.array): a matrix/vector of labels \n",
    "        _theta (numpy.array): a matrix/vector of parameters being trained \n",
    "        hyperparams (dict): a dictionary where the key is the hyperparameter name \n",
    "                            and values is the hyperparameter value\n",
    "                            \n",
    "    Returns:\n",
    "        _theta (numpy.array): a matrix/vector of parameters updated after training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "    return _theta\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5c5f2",
   "metadata": {},
   "source": [
    "## $\\color{Red}{Question\\ 3.4}$ Train and Monitor the Stochastic Ridge Regression Model\n",
    "In this question, you are expected to use the previously defined stochastic gradient training function (`train_stoch_ridge_reg`) to train a ridge regression model using the `X_, y_` data structures from before. Record the relevant loss values computed in each iteration to analyse if the loss is diminishing over time. \n",
    "\n",
    "- Implement `train_entire_model` function to take the dataset and train the model over multiple iterations. \n",
    "    - Run the model for 2000 iterations to reduce the loss values over time\n",
    "- Record the loss $\\mathcal{L}$ values of the model over all the iterations.\n",
    "- pass the list of losses as output from this function.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- Set the initial weights (thetas) to a normal distribution scattered around mean 0. \n",
    "- As the penalisation constant in the Ridge Regression, 0.1 is a good value to use\n",
    "- A learning rate between 1e-6 and 1e-10 may be suitable for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_entire_model(X_, y_, hyperparams):\n",
    "    \"\"\"\n",
    "    takes data, hyperparameters and returns the list of losses \n",
    "    \n",
    "    Params:\n",
    "        X_ (numpy.array): a matrix/vector of features \n",
    "        y_ (numpy.array): a matrix/vector of labels \n",
    "        hyperparams (dict): a dictionary where the key is the hyperparameter name \n",
    "                            and values is the hyperparameter value\n",
    "                            \n",
    "    Returns:\n",
    "        losses ([float]): list of loss values for each iteration of learning\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your Code Here\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = X_, y_ # Reusing data structures from before\n",
    "\n",
    "hyperparameters = {\n",
    "    # Your Code Here\n",
    "    \n",
    "}\n",
    "\n",
    "losses = train_entire_model(X_, y_, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2b5c4",
   "metadata": {},
   "source": [
    "- Implement the `visualise_loss_values` function to use the appropriate visualisations to plot the loss values in a meaningful way.\n",
    "- The function does not have to return anything. Display the visualisation as a step within the implemented function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_loss_values(loss_values):\n",
    "    \"\"\"\n",
    "    takes relevant loss values and plots the loss values in the dataset over the iterations (epochs).\n",
    "    \n",
    "    Params:\n",
    "        loss_values (dict): a dictionary that contains the loss values where key is the loss type\n",
    "                            and values are the loss values.\n",
    "    \"\"\"\n",
    "    # Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3dfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_loss_values(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548ac2e",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "- Does the loss get smaller over time? In either case, explain the reason behind it.\n",
    "- For both the regularisation factor and the learning rate, plot the loss with a sample of larger and smaller values for each hyperparameter. Observe how the loss changes for each hyperparameter _individually_ and draw hypotheses justifying these observations. \n",
    "    - __Note: you do not need to interpret the joint effects of changing the hyperparameter values__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde7da9",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088b7a3",
   "metadata": {},
   "source": [
    "## - End of Coursework - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
